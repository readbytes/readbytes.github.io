<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Pandas for Data Science Input and Output with Pandas</title>
<link rel='shortcut icon' href='https://readbytes.github.io/images/favicon.ico'>
<link href="https://fonts.googleapis.com/css2?family=Merriweather&display=swap" rel="stylesheet" />
<link href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.16/codemirror.min.css" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.16/codemirror.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.16/theme/dracula.min.css"><style>
html {scroll-behavior: smooth;}  
body {font-family: 'Merriweather', serif;;margin: 0;padding: 2rem 1rem;font-size: 15px;line-height: 1.5;transition: background-color 0.3s, color 0.3s;}
.container {max-width: 750px;margin: 0 auto;padding: 1rem 2rem;}
.light-mode {background-color: #f8f7f5;color: #333;} 
.dark-mode {background-color: #121212;color: #e0e0e0;}
a { text-decoration: none;transition: color 0.2s;}
a:hover {text-decoration: underline;}
.light-mode a {color: #555;}
.dark-mode a {color: #aaa;}
</style><style>
.related-book-list {display: flex;flex-wrap: wrap;gap: 20px;}
.related-books {margin-top: 40px;}
.related-books h2 {font-size: 22px;margin-bottom: 20px;border-bottom: 2px solid #eee;padding-bottom: 8px;}
.light-mode .related-books h2 {color: #333;border-color: #eee;}
.dark-mode .related-books h2 {color: #ddd;border-color: #333;}
</style><style>
.book-cover {width: 130px;height: 180px;font-family: Arial, sans-serif;position: relative;overflow: hidden;box-shadow: 2px 2px 4px rgba(0,0,0,0.1);}
.book-cover-bottom-stripe {position: absolute;bottom: 0;left: 0;height: 5px;width: 100%;}
.book-cover-title {position: absolute;width: 100%;text-align: center;font-weight: bold;}
.book-cover-icon {position: absolute;left: 50%;transform: translateX(-50%);display: flex;align-items: center;justify-content: center;}
.book-cover-author {position: absolute;bottom: 10px;width: 100%;text-align: center;font-size: 8px;color: #333;}
</style><style>
.book-title-toc {font-size: 32px;font-weight: bold; }
.book-subtitle-toc {font-size: 18px;margin-top: 8px;font-style: italic;}
.book-header {text-align: center;margin-bottom: 40px;}

.toc-container {border-radius: 10px;padding: 30px;margin-bottom: 40px;box-shadow: 0 8px 20px rgba(0,0,0,0.05);}
h1 {font-size: 24px;text-align: center;margin-bottom: 30px;letter-spacing: 1px;padding-bottom: 10px;}
.toc-list,.toc-section-list {list-style: none;padding: 0;margin: 0;}
.toc-section-list {padding-left: 18px;margin-top: 6px;margin-bottom: 20px; }
.toc-chapter {padding: 20px 0;}
.chapter-title,.toc-section {display: flex;justify-content: space-between;padding-top: 4px;}
.chapter-title {font-size: 17px;font-weight: bold;}
.chapter-page,.section-page {font-style: italic;}
 
 
.light-mode .book-title-toc,.light-mode .chapter-title,.light-mode .book-name {color: #222;}
.light-mode .book-subtitle-toc,.light-mode .book-sub,.light-mode .chapter-page,.light-mode .section-page {color: #666;}
.light-mode .toc-container { background: #fff;border: 1px solid #ddd;}
.light-mode h1 {border-bottom: 2px solid #eee;color: #222;}
.light-mode .toc-section {  color: #444;}

.light-mode .book-cover { border: 1px solid #ccc;box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);}
.light-mode .book-title,.light-mode .series-name {color: #fff;}
.light-mode .book-subtitle,.light-mode .book-footer {color: #aaa;}

.dark-mode .book-title-toc,.dark-mode .chapter-title,.dark-mode .book-name {color: #f5f5f5;}
.dark-mode .book-subtitle-toc,.dark-mode .book-sub,.dark-mode .chapter-page,.dark-mode .section-page {color: #aaa;}
.dark-mode .toc-container {background: #1e1e1e;border: 1px solid #444;}

.dark-mode h1 {border-bottom: 2px solid #333;color: #eee;}
.dark-mode .toc-section {color: #bbb;}

.dark-mode .related-books h2 {color: #ddd;border-bottom: 2px solid #333;}
.dark-mode .book-title,.dark-mode .series-name {color: #fff;}
.dark-mode .book-subtitle,.dark-mode .book-footer {color: #bbb;}
.dark-mode .toc-section {color: #ddd;}

@media (max-width: 600px) {
  .chapter-title,
  .toc-section {
    flex-direction: column;
    align-items: flex-start;
  }

  .chapter-page,
  .section-page {
    margin-top: 4px;
  }
}

</style><style>
.light-mode .container {box-shadow: 0 0 15px rgba(0,0,0,0.1);}
.dark-mode .container {box-shadow: 0 0 15px rgba(255, 255, 255, 0.05);}

h1, h2, h3 {font-weight: 600;margin-top: 2.5rem;margin-bottom: 1rem;line-height: 1.2;}
h1 { font-size: 1.8rem; }
h2 { font-size: 1.4rem; }
h3 { font-size: 1.2rem; }

table {width: 100%;border-collapse: collapse;font-family: sans-serif;font-size: 1em;margin: 1em 0;}
th, td {padding: 0.6em 1em;text-align: left;border: 1px solid;}
tr:nth-child(even) {  background-color: inherit;}
tr:hover { background-color: inherit;}

code {color: #d35400;}

.chapter-navi-section {display: flex;justify-content: space-between;align-items: center;padding-bottom: 10px;padding-top: 10px;}
.nav-link {color: inherit;text-decoration: none;opacity: 0.5;transition: opacity 0.3s ease, text-decoration 0.3s ease;}
.nav-link:hover {opacity: 0.9;text-decoration: underline;}
.prev { text-align: left; }
.toc-link { text-align: center; }
.next { text-align: right; }

.download-section {display: flex;align-items: center;justify-content: center;gap: 2rem;padding: 2rem 1rem;max-width: 600px;margin: 3rem auto;border-radius: 12px;box-shadow: 0 4px 10px rgba(0,0,0,0.05);}
.download-info h2 {margin: 0 0 0.5rem;font-size: 1.2rem;}
.format-label {margin: 0 0 0.5rem;font-size: 0.95rem;}
.download-buttons {display: flex;gap: 1rem;}
.download-button {background-color: #4A90E2;color: white;padding: 0.5em 1.2em;border-radius: 25px;font-size: 0.95rem;text-decoration: none;transition: background-color 0.3s ease;}
.download-button:hover {background-color: #357ABD;}

.code-block {position: relative;margin-bottom: 1em;}
.copy-button {background: transparent;color: white;position: absolute;top: 8px;right: 8px;border: none;padding: 4px 8px;font-size: 12px;border-radius: 4px;cursor: pointer;z-index: 1;}
.copy-button:hover {background-color: #0056b3;}

.snippet-container {overflow: hidden;}
.snippet-header {padding: 0.75rem 1rem;cursor: pointer;font-size: 1rem;background-color: #eeeeee;color:  #111111; border-radius: 8px;cursor: pointer;box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
.snippet-body {display: none;font-family: monospace;}
.snippet-container.open .snippet-body {display: block;}

.CodeMirror {border: 2px solid #ccc;border-radius: 4px;resize: vertical;}

.light-mode .format-label {color: #888;}
.light-mode th {background-color: #f2f2f2;}
.light-mode tr:nth-child(even) {background-color: #fafafa;}
.light-mode tr:hover {background-color: #e6f7ff;}

.dark-mode .snippet-header {background-color: #333;color:  #ddd; }
.dark-mode .format-label {color: #aaa;}
.dark-mode th {background-color: #333;color: #fff;}
.dark-mode td {border-color: #444;}
.dark-mode tr:nth-child(even) {background-color: #2a2a2a;}
.dark-mode tr:hover {background-color: #2c3e50;}


.button-group-run-edit {display: flex;width: 100%;gap: 1rem;}
.button-run-edit {flex: 1;padding: 1rem;font-size: 1rem;font-weight: 600;border: none;border-radius: 8px;cursor: pointer;transition: background 0.3s, color 0.3s;}

.light-mode .button-run-edit {background-color: #f0f0f0;color: #222;box-shadow: 0 0 10px rgba(0, 0, 0, 0.05);}
.light-mode .button-run-edit:hover {background-color: #e0e0e0;}

.dark-mode .button-run-edit {background-color: #2a2a2a;color: #f5f5f5;box-shadow: 0 0 10px rgba(255, 255, 255, 0.05);}
.dark-mode .button-run-edit:hover {background-color: #3a3a3a;}

button { padding: 0.5em 1em; background: green; color: white; border: none; cursor: pointer; }
button:hover { background: #1e7e34; }
.result_iframe { width:99%; margin-top: 1em;  resize: both;background-color: #515b63;border:1px solid #ccc;}   

.dialog-backdrop {position: fixed;top: 0;left: 0;width: 100vw;height: 100vh;background: rgba(0,0,0,0.5);display: none;justify-content: center;align-items: center;z-index: 10;}
.dialog {background: #90979e;padding: 20px;width: 90vw;height: 80vh;border-radius: 8px;box-shadow: 0 0 20px rgba(0,0,0,0.3);display: flex;flex-direction: column;}
.dialog-content {display: flex;gap: 20px;margin-top: 10px;height: calc(100% - 40px);}
.editor-container, .preview-container {flex: 1;height: 100%;max-height: 100%;overflow: hidden; }
.result_iframe_dialog {width: 100%;height: 100%;resize: both;border:1px solid #ccc;overflow: auto; }   
.CodeMirror {width: 100% !important;height: 100% !important;}
</style>
</head>
<body>
<script>const mode = localStorage.getItem('mode') || 'light';document.documentElement.classList.add(`${mode}-mode`);</script>  
<div class="container"><div class = "chapter-navi-section">
<a href="pandas-for-data-science-time-series-and-date-functionality.htm" class="nav-button prev">←</a>
<a href='pandas-for-data-science.htm#input-and-output-with-pandas' class="nav-button toc-link">Index</a>
<a href="pandas-for-data-science-visualization-with-pandas.htm" class="nav-button next">→</a>
</div>
<div class='book-header'><h1 class='book-title-toc' id = 'top'>Input and Output with Pandas</h1><h3 class='book-subtitle-toc'>Pandas for Data Science</h3></div><h2 id='reading-and-writing-csv-excel-json-sql'>10.1 Reading and Writing CSV, Excel, JSON, SQL</h2><p>Pandas makes it straightforward to read from and write to various data file formats and databases, allowing seamless integration with your data workflow. This section covers essential I/O functions: how to load and save <strong>CSV</strong>, <strong>Excel</strong>, <strong>JSON</strong>, and <strong>SQL</strong> data, along with common parameters and pitfalls.</p><h3 id="reading-and-writing-csv-files">Reading and Writing CSV Files</h3><p>CSV (Comma-Separated Values) is one of the most common data formats.</p><p><strong>Reading a CSV:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">import pandas as pd

# Load CSV file
df = pd.read_csv('data/sales.csv', delimiter=',', encoding='utf-8', header=0, index_col=0)
print(df.head())</code></pre>
</div><ul>
 <li><code>delimiter</code> (or <code>sep</code>): Specifies the column separator (default is <code>,</code>).</li>
 <li><code>encoding</code>: Useful when working with non-ASCII characters (e.g., <code>'utf-8'</code>).</li>
 <li><code>header</code>: Row number(s) to use as the column names (default is 0).</li>
 <li><code>index_col</code>: Column(s) to use as the row index.</li>
</ul><p><strong>Writing a CSV:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">df.to_csv('data/cleaned_sales.csv', index=True, encoding='utf-8')</code></pre>
</div><ul>
 <li><code>index</code>: Whether to write row labels (index) to the file.</li>
 <li>Always verify if the index should be saved to avoid duplicates or confusion later.</li>
</ul><h3 id="reading-and-writing-excel-files">Reading and Writing Excel Files</h3><p>Excel files (<code>.xlsx</code>, <code>.xls</code>) are popular in business.</p><p><strong>Reading Excel:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python"># Read Excel sheet
excel_df = pd.read_excel('data/report.xlsx', sheet_name='Sheet1', index_col=0)
print(excel_df.head())</code></pre>
</div><ul>
 <li><code>sheet_name</code>: Name or number of the sheet to read.</li>
 <li><code>index_col</code>: Column to use as index.</li>
 <li>Pandas uses <code>openpyxl</code> or <code>xlrd</code> internally (ensure packages are installed).</li>
</ul><p><strong>Writing Excel:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">excel_df.to_excel('data/output_report.xlsx', sheet_name='Summary', index=False)</code></pre>
</div><ul>
 <li>You can write multiple DataFrames to different sheets using <code>ExcelWriter</code>.</li>
</ul><h3 id="reading-and-writing-json-files">Reading and Writing JSON Files</h3><p>JSON is common for nested and hierarchical data.</p><p><strong>Reading JSON:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">json_df = pd.read_json('data/data.json', encoding='utf-8')
print(json_df.head())</code></pre>
</div><ul>
 <li><code>orient</code> parameter controls the expected JSON format (<code>'records'</code>, <code>'split'</code>, etc.).</li>
 <li>JSON often requires preprocessing if deeply nested.</li>
</ul><p><strong>Writing JSON:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">json_df.to_json('data/output.json', orient='records', lines=True)</code></pre>
</div><ul>
 <li><code>orient='records'</code> outputs a list of JSON objects.</li>
 <li><code>lines=True</code> writes JSON objects per line (useful for streaming).</li>
</ul><h3 id="reading-and-writing-sql-databases">Reading and Writing SQL Databases</h3><p>Pandas can read from and write to SQL databases, facilitating integration with persistent data storage.</p><p><strong>Reading from SQL:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">import sqlite3

# Connect to SQLite database
conn = sqlite3.connect('data/database.db')

# Read SQL query into DataFrame
sql_df = pd.read_sql('SELECT * FROM sales_data WHERE amount &gt; 100', conn)
print(sql_df.head())</code></pre>
</div><ul>
 <li>You can use any SQLAlchemy-compatible database.</li>
 <li>The query can be a raw SQL string or SQLAlchemy expression.</li>
</ul><p><strong>Writing to SQL:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python"># Write DataFrame to SQL table (replace if exists)
df.to_sql('cleaned_sales', conn, if_exists='replace', index=False)</code></pre>
</div><ul>
 <li><code>if_exists</code> can be <code>'fail'</code>, <code>'replace'</code>, or <code>'append'</code>.</li>
 <li>Be careful with the schema and data types when writing.</li>
</ul><h3 id="common-pitfalls-and-tips">Common Pitfalls and Tips</h3><ul>
 <li><p><strong>Missing Data:</strong> When reading, missing values might appear as <code>NaN</code>. Use <code>na_values</code> to specify additional representations.</p>
  <div class="code-block">
   <button class="copy-button" onclick="copyCode(this)">▯</button>
   <pre><code class="language-python">pd.read_csv('data.csv', na_values=['NA', 'missing'])</code></pre>
  </div></li>
 <li><p><strong>Data Types:</strong> Pandas infers data types, but sometimes conversion is needed after loading.</p>
  <div class="code-block">
   <button class="copy-button" onclick="copyCode(this)">▯</button>
   <pre><code class="language-python">df['date'] = pd.to_datetime(df['date'])
df['quantity'] = df['quantity'].astype(int)</code></pre>
  </div></li>
 <li><p><strong>Index Handling:</strong> When saving, be explicit about saving indexes to avoid duplications or misalignments on reload.</p></li>
 <li><p><strong>Encoding Issues:</strong> Always specify the correct encoding, especially with non-English data, to prevent errors.</p></li>
</ul><h3 id="summary">Summary</h3><table>
 <thead>
  <tr>
   <th>Format</th>
   <th>Read Function</th>
   <th>Write Function</th>
   <th>Key Parameters</th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>CSV</td>
   <td><code>read_csv()</code></td>
   <td><code>to_csv()</code></td>
   <td><code>delimiter</code>, <code>encoding</code>, <code>index_col</code></td>
  </tr>
  <tr>
   <td>Excel</td>
   <td><code>read_excel()</code></td>
   <td><code>to_excel()</code></td>
   <td><code>sheet_name</code>, <code>index_col</code></td>
  </tr>
  <tr>
   <td>JSON</td>
   <td><code>read_json()</code></td>
   <td><code>to_json()</code></td>
   <td><code>orient</code>, <code>lines</code></td>
  </tr>
  <tr>
   <td>SQL</td>
   <td><code>read_sql()</code></td>
   <td><code>to_sql()</code></td>
   <td><code>if_exists</code>, <code>index</code>, connection</td>
  </tr>
 </tbody>
</table><p>With these core I/O functions, you can efficiently move data between pandas and various external sources, enabling smooth data ingestion and export workflows.</p><div class = "chapter-navi-section">
<a href="#top" class="nav-button prev">↑</a>
<a href='pandas-for-data-science.htm#input-and-output-with-pandas' class="nav-button toc-link">Index</a>
<a href="#bottom" class="nav-button next">↓</a>
</div>
<h2 id='handling-large-datasets-chunking-and-efficient-i-o'>10.2 Handling Large Datasets: Chunking and Efficient I/O</h2><p>When working with large datasets, loading an entire file into memory at once can be impractical or even impossible due to memory constraints. Pandas provides several strategies to efficiently handle large data files, enabling you to process data incrementally or optimize resource usage.</p><h3 id="the-challenge-of-large-files">The Challenge of Large Files</h3><p>Large files — often gigabytes in size — can cause your system to run out of memory if loaded fully. This can lead to crashes or extremely slow performance. To manage this, we use <strong>chunking</strong>, which reads data in smaller pieces, allowing for incremental processing.</p><h3 id="reading-files-in-chunks-with-chunksize">Reading Files in Chunks with <code>chunksize</code></h3><p>The <code>chunksize</code> parameter in <code>read_csv()</code> (and some other readers) lets you read a file piece by piece as an iterator of DataFrames:</p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">import pandas as pd

chunk_iter = pd.read_csv('large_data.csv', chunksize=100000)

for i, chunk in enumerate(chunk_iter):
    print(f"Processing chunk {i+1}")
    # Example operation: calculate sum of a column in the chunk
    total_sales = chunk['sales'].sum()
    print(f"Total sales in chunk {i+1}: {total_sales}")</code></pre>
</div><ul>
 <li>Each <code>chunk</code> is a DataFrame with <code>chunksize</code> rows.</li>
 <li>You can process each chunk independently, then aggregate results to avoid loading the full file.</li>
</ul><h3 id="aggregating-results-across-chunks">Aggregating Results Across Chunks</h3><p>Suppose you want the overall total sales without loading the entire dataset:</p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">total_sales = 0
for chunk in pd.read_csv('large_data.csv', chunksize=100000):
    total_sales += chunk['sales'].sum()

print(f"Overall total sales: {total_sales}")</code></pre>
</div><p>This technique lets you efficiently summarize or filter large data.</p><h3 id="streaming-and-memory-management">Streaming and Memory Management</h3><ul>
 <li><strong>Streaming:</strong> Using <code>chunksize</code> creates a lazy iterator, reading only part of the file at a time.</li>
 <li><strong>Memory:</strong> After processing a chunk, Python’s garbage collector frees that memory, avoiding overload.</li>
 <li><strong>Selective columns:</strong> Use the <code>usecols</code> parameter to read only necessary columns, reducing memory usage.</li>
</ul><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">chunk_iter = pd.read_csv('large_data.csv', chunksize=100000, usecols=['date', 'sales'])</code></pre>
</div><h3 id="writing-data-efficiently-in-chunks">Writing Data Efficiently in Chunks</h3><p>When processing and writing large data in pieces, use the <code>mode</code> and <code>header</code> parameters in <code>to_csv()</code> to append chunks to a file without overwriting:</p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">for i, chunk in enumerate(pd.read_csv('large_data.csv', chunksize=100000)):
    processed_chunk = chunk[chunk['sales'] &gt; 1000]  # filter example
    if i == 0:
        processed_chunk.to_csv('filtered_sales.csv', index=False, mode='w', header=True)
    else:
        processed_chunk.to_csv('filtered_sales.csv', index=False, mode='a', header=False)</code></pre>
</div><p>This approach allows you to create a filtered or transformed dataset incrementally.</p><h3 id="optimizing-reading-and-writing">Optimizing Reading and Writing</h3><ul>
 <li><p><strong>Specify data types:</strong> Use the <code>dtype</code> parameter to reduce memory by assigning efficient types upfront.</p>
  <div class="code-block">
   <button class="copy-button" onclick="copyCode(this)">▯</button>
   <pre><code class="language-python">dtypes = {'sales': 'float32', 'product_id': 'int32'}
chunk_iter = pd.read_csv('large_data.csv', chunksize=100000, dtype=dtypes)</code></pre>
  </div></li>
 <li><p><strong>Compression:</strong> Read/write compressed files (<code>.gz</code>, <code>.zip</code>) by setting <code>compression</code> parameter, saving disk space and I/O time.</p></li>
</ul><h3 id="summary">Summary</h3><ul>
 <li>Large files can be processed efficiently using <strong>chunking</strong> with <code>chunksize</code>.</li>
 <li>Process each chunk independently, aggregating or filtering as needed.</li>
 <li>Control memory use with selective columns (<code>usecols</code>), specifying <code>dtype</code>, and compressing files.</li>
 <li>Writing in chunks supports incremental data transformations and filtered output.</li>
 <li>These techniques make Pandas suitable for big data workflows without needing specialized tools.</li>
</ul><p>Mastering chunking and efficient I/O ensures your data analysis scales gracefully with data volume and system resources.</p><div class = "chapter-navi-section">
<a href="#top" class="nav-button prev">↑</a>
<a href='pandas-for-data-science.htm#input-and-output-with-pandas' class="nav-button toc-link">Index</a>
<a href="#bottom" class="nav-button next">↓</a>
</div>
<h2 id='working-with-hdf5-and-parquet-files'>10.3 Working with HDF5 and Parquet Files</h2><p>When working with large datasets or requiring fast disk I/O and efficient storage, binary file formats like <strong>HDF5</strong> and <strong>Parquet</strong> offer significant advantages over plain text formats like CSV or JSON. These formats provide compression, faster read/write speeds, and better integration with big data ecosystems.</p><h3 id="hdf5-format">HDF5 Format</h3><p>HDF5 (Hierarchical Data Format version 5) is a versatile, high-performance binary format designed for storing large amounts of numerical data. It supports complex data hierarchies and is widely used in scientific computing.</p><p>Pandas provides built-in support for HDF5 through the <code>read_hdf()</code> and <code>to_hdf()</code> functions.</p><p><strong>Writing a DataFrame to HDF5:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">import pandas as pd

df = pd.DataFrame({
    'date': pd.date_range('2024-01-01', periods=5),
    'value': [10, 20, 30, 40, 50]
})

# Write to HDF5 file under the key 'data'
df.to_hdf('data_store.h5', key='data', mode='w')</code></pre>
</div><p><strong>Reading from HDF5:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">df_loaded = pd.read_hdf('data_store.h5', key='data')
print(df_loaded)</code></pre>
</div><ul>
 <li><strong><code>key</code></strong> specifies the group name inside the HDF5 file, allowing multiple datasets in one file.</li>
 <li>HDF5 supports compression and fast random access.</li>
 <li>It works well for numeric or tabular data and supports querying subsets.</li>
</ul><h3 id="parquet-format">Parquet Format</h3><p>Parquet is a columnar storage file format optimized for analytics workloads. It offers efficient compression and encoding schemes, making it a go-to format in big data tools like Apache Spark, Hadoop, and cloud platforms.</p><p>Pandas supports Parquet files with <code>read_parquet()</code> and <code>to_parquet()</code> functions, but requires either <code>pyarrow</code> or <code>fastparquet</code> as a dependency.</p><p><strong>Writing a DataFrame to Parquet:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">df.to_parquet('data.parquet', index=False)</code></pre>
</div><p><strong>Reading from Parquet:</strong></p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">df_parquet = pd.read_parquet('data.parquet')
print(df_parquet)</code></pre>
</div><ul>
 <li>Parquet files store data by column, enabling faster reads for column-based queries.</li>
 <li>The format supports schema evolution, nested data, and is interoperable across many systems.</li>
 <li>Common in machine learning pipelines and cloud data lakes.</li>
</ul><h3 id="when-to-use-hdf5-vs-parquet">When to Use HDF5 vs Parquet?</h3><table>
 <thead>
  <tr>
   <th>Feature</th>
   <th>HDF5</th>
   <th>Parquet</th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>Data model</td>
   <td>Hierarchical, flexible</td>
   <td>Columnar, optimized for tables</td>
  </tr>
  <tr>
   <td>Use case</td>
   <td>Scientific computing, complex datasets</td>
   <td>Big data analytics, cloud storage</td>
  </tr>
  <tr>
   <td>Compression</td>
   <td>Yes</td>
   <td>Yes</td>
  </tr>
  <tr>
   <td>Supported by</td>
   <td>Pandas, HDF5 libraries</td>
   <td>Pandas, Apache Arrow ecosystem</td>
  </tr>
  <tr>
   <td>Performance</td>
   <td>Fast for complex queries</td>
   <td>Fast columnar queries</td>
  </tr>
  <tr>
   <td>Interoperability</td>
   <td>Limited outside scientific tools</td>
   <td>Broad, supports many platforms</td>
  </tr>
 </tbody>
</table><h3 id="practical-example-combining-formats">Practical Example: Combining Formats</h3><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python"># Create example DataFrame
df = pd.DataFrame({
    'id': [1, 2, 3, 4],
    'category': ['A', 'B', 'A', 'B'],
    'value': [10, 20, 30, 40]
})

# Save to HDF5
df.to_hdf('example.h5', key='df', mode='w')

# Save to Parquet
df.to_parquet('example.parquet')

# Load both
df_hdf = pd.read_hdf('example.h5', 'df')
df_parquet = pd.read_parquet('example.parquet')

print("From HDF5:\n", df_hdf)
print("\nFrom Parquet:\n", df_parquet)</code></pre>
</div><h3 id="summary">Summary</h3><ul>
 <li><strong>HDF5</strong> is great for hierarchical datasets and works well in scientific environments needing flexible data storage.</li>
 <li><strong>Parquet</strong> shines in analytics, offering fast, compressed columnar storage compatible with big data tools.</li>
 <li>Both formats greatly improve performance and reduce storage compared to CSV or JSON.</li>
 <li>Pandas’ <code>read_hdf()</code>, <code>to_hdf()</code>, <code>read_parquet()</code>, and <code>to_parquet()</code> make working with these formats easy and efficient.</li>
</ul><p>Adopting these binary formats can significantly enhance your data pipeline's speed and scalability, especially for large-scale or production-grade workflows.</p><div class = "chapter-navi-section">
<a href="#top" class="nav-button prev">↑</a>
<a href='pandas-for-data-science.htm#input-and-output-with-pandas' class="nav-button toc-link">Index</a>
<a href="#bottom" class="nav-button next">↓</a>
</div>
<h2 id='practical-examples-data-persistence-and-exchange'>10.4 Practical Examples: Data Persistence and Exchange</h2><p>In real-world data science projects, you often need to load data from multiple sources, clean or transform it, then save it in formats suitable for sharing, reporting, or future analysis. This section walks through a practical example demonstrating these steps using Pandas, highlighting best practices for choosing file formats and ensuring data integrity.</p><h3 id="scenario-combining-sales-and-customer-data">Scenario: Combining Sales and Customer Data</h3><p>Suppose you have two data sources:</p><ul>
 <li>A <strong>CSV file</strong> with monthly sales transactions.</li>
 <li>An <strong>Excel file</strong> with customer details.</li>
</ul><p>Your goal is to merge these datasets, perform some analysis, then save the cleaned data in formats that optimize future access and sharing.</p><h3 id="step-1-read-data-from-multiple-sources">Step 1: Read Data from Multiple Sources</h3><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">import pandas as pd

# Read sales data from CSV
sales_df = pd.read_csv('sales_jan.csv')

# Read customer data from Excel (first sheet)
customers_df = pd.read_excel('customers.xlsx', sheet_name='Sheet1')

print(sales_df.head())
print(customers_df.head())</code></pre>
</div><h3 id="step-2-data-cleaning-and-merging">Step 2: Data Cleaning and Merging</h3><p>Let's ensure consistency, handle missing values, and merge the datasets on <code>customer_id</code>.</p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python"># Fill missing sales amounts with 0
sales_df['amount'] = sales_df['amount'].fillna(0)

# Standardize customer IDs (ensure same type)
sales_df['customer_id'] = sales_df['customer_id'].astype(str)
customers_df['customer_id'] = customers_df['customer_id'].astype(str)

# Merge sales with customer info (left join to keep all sales)
merged_df = pd.merge(sales_df, customers_df, on='customer_id', how='left')

print(merged_df.info())</code></pre>
</div><h3 id="step-3-analyze-and-add-features">Step 3: Analyze and Add Features</h3><p>Add a new feature: categorize sales into 'High' and 'Low' based on amount.</p><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python">merged_df['sales_category'] = merged_df['amount'].apply(lambda x: 'High' if x &gt; 500 else 'Low')</code></pre>
</div><h3 id="step-4-save-processed-data-for-different-use-cases">Step 4: Save Processed Data for Different Use Cases</h3><ul>
 <li><strong>CSV:</strong> Simple sharing or quick inspection.</li>
 <li><strong>Parquet:</strong> Efficient storage and future analysis with fast loading.</li>
 <li><strong>Excel:</strong> For business users who prefer spreadsheets.</li>
</ul><div class="code-block">
 <button class="copy-button" onclick="copyCode(this)">▯</button>
 <pre><code class="language-python"># Save to CSV (without index for clean file)
merged_df.to_csv('processed_sales.csv', index=False)

# Save to Parquet (efficient binary format)
merged_df.to_parquet('processed_sales.parquet', index=False)

# Save to Excel (multiple sheets possible if needed)
merged_df.to_excel('processed_sales.xlsx', index=False, sheet_name='SalesData')</code></pre>
</div><h3 id="practical-tips-for-format-choice-and-data-integrity">Practical Tips for Format Choice and Data Integrity</h3><ul>
 <li><strong>CSV</strong> is widely compatible but lacks support for data types and compression. Avoid for very large datasets.</li>
 <li><strong>Parquet</strong> is ideal for performance and storing data types but requires compatible tools for reading.</li>
 <li><strong>Excel</strong> is convenient for reporting but can be slower and less suited for very large data.</li>
 <li>Always check and <strong>standardize data types</strong> before merging to avoid subtle bugs.</li>
 <li>Use <code>index=False</code> to avoid saving unnecessary indexes unless explicitly needed.</li>
 <li>Consider <strong>compression options</strong> (<code>compression='gzip'</code> in CSV or Parquet) to save disk space.</li>
</ul><h3 id="summary">Summary</h3><p>This example demonstrated how to:</p><ul>
 <li>Load data from CSV and Excel files.</li>
 <li>Clean and merge datasets using Pandas.</li>
 <li>Add meaningful features.</li>
 <li>Save data in multiple formats tailored to different use cases.</li>
</ul><p>By mastering data persistence and exchange techniques, you ensure smooth collaboration, efficient workflows, and reproducible data science projects.</p><div class = "chapter-navi-section">
<a href="pandas-for-data-science-time-series-and-date-functionality.htm" class="nav-button prev">←</a>
<a href='pandas-for-data-science.htm#input-and-output-with-pandas' class="nav-button toc-link">Index</a>
<a href="pandas-for-data-science-visualization-with-pandas.htm" class="nav-button next">→</a>
</div>
<section class="download-section">
  <div class="book-cover" style="background-color: #f9f6f1;border: 1px solid #ccc;"> 
    <div class="book-cover-title" style="font-size: 18px;color: #333;top: 20px;">Pandas for Data Science</div>
    <div class="book-cover-author">readbytes</div>
    <div class="book-cover-bottom-stripe" style="background-color: #333;"></div>
    <img class="book-cover-icon" style="width: 90px;height: 90px;top: 70px;" src="data:image/png;base64,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"/>
  </div>
  <div class="download-info">
    <h2 id='bottom'>Download This Ebook</h2>
    <p class="format-label">Available formats:</p>
    <div class="download-buttons">
      <a href="pandas-for-data-science.pdf" class="download-button">📄 PDF</a>
      <a href="pandas-for-data-science.epub" class="download-button">📘 EPUB</a>
    </div>
  </div>
</section><div class='related-books'>
<h2>Python Data Science Books</h2>
<div class='related-book-list'>
<a href="pandas-for-data-science.htm">
<div class="book-cover" style="background-color: #f9f6f1;border: 1px solid #ccc;"> 
    <div class="book-cover-title" style="font-size: 18px;color: #333;top: 20px;">Pandas for Data Science</div>
    <div class="book-cover-author">readbytes</div>
    <div class="book-cover-bottom-stripe" style="background-color: #333;"></div>
    <img class="book-cover-icon" style="width: 90px;height: 90px;top: 70px;" src="data:image/png;base64,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"/>
  </div>
</a>



<a href='python.htm'><div class='book-cover' style='background-color: #f9f6f1;color: #111111;border: 1px solid #ccc;display: flex;justify-content: center;align-items: center;text-align: center;'>More Python Books</div></a>
</div>
</div><script>
function copyCode(button) {const code = button.nextElementSibling.innerText;navigator.clipboard.writeText(code).then(() => {button.textContent = 'Copied!';setTimeout(() => { button.textContent = 'Copy'; }, 1500);});}
</script></div>
<style>
.site-footer {margin-top: 60px;padding: 20px 0;border-top: 1px solid #eee;text-align: center;font-size: 14px;}
.site-footer a {text-decoration: none;}
.light-mode .site-footer {color: #777;border-color: #eee;}
.dark-mode .site-footer {color: #888;border-color: #333;}
.light-mode .site-footer a {color: #555;}
.dark-mode .site-footer a {color: #aaa;}
.site-footer a:hover {text-decoration: underline;}    
</style>
<footer class="site-footer">
<nav><a href="https://readbytes.github.io">Home</a> |Email:<script type="text/javascript">
var part1 = 'yinpeng';var part6 = '263';var part2 = Math.pow(2,6);var part3 = String.fromCharCode(part2);var part4 = 'hotmail dot com';var part5 = part1 + String.fromCharCode(part2) + part4;document.write(part1 + part6 + part3 + part4);
</script>
| <a id="mode-toggle" href="#">Toggle Dark Mode</a>
</nav><p>© 2025 — All rights reserved.</p></footer>
<script>
const toggleButton = document.getElementById('mode-toggle');
const body = document.body;
const savedMode = localStorage.getItem('mode') || 'light';
body.classList.add(savedMode + '-mode');
toggleButton.addEventListener('click', () => {
      const isDark = body.classList.contains('dark-mode');
      body.classList.toggle('dark-mode', !isDark);
      body.classList.toggle('light-mode', isDark);
      localStorage.setItem('mode', isDark ? 'light' : 'dark');
});
function copyCode(button) {const code = button.nextElementSibling.innerText;navigator.clipboard.writeText(code).then(() => {button.textContent = 'Copied!';setTimeout(() => { button.textContent = 'Copy'; }, 1500);});}
</script>
</body>
</html>